{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from product_quantization import ProductQuantizationKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on MNIST data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowed from; https://www.cntk.ai/pythondocs/CNTK_103A_MNIST_DataLoader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load MNIST images and unpack into train and test set.\n",
    "# - loadData reads a image and formats it into a 28x28 long array\n",
    "# - loadLabels reads the corresponding label data, one for each image\n",
    "# - load packs the downloaded image and label data into a combined format to be read later by\n",
    "#   the CNTK text reader\n",
    "\n",
    "def loadData(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    print ('Done.')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x3080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))[0]\n",
    "            if n != cimg:\n",
    "                raise Exception('Invalid file: expected {0} entries.'.format(cimg))\n",
    "            crow = struct.unpack('>I', gz.read(4))[0]\n",
    "            ccol = struct.unpack('>I', gz.read(4))[0]\n",
    "            if crow != 28 or ccol != 28:\n",
    "                raise Exception('Invalid file: expected 28 rows/cols per image.')\n",
    "            # Read data.\n",
    "            res = np.fromstring(gz.read(cimg * crow * ccol), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, crow * ccol))\n",
    "\n",
    "def loadLabels(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    print ('Done.')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x1080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))\n",
    "            if n[0] != cimg:\n",
    "                raise Exception('Invalid file: expected {0} rows.'.format(cimg))\n",
    "            # Read labels.\n",
    "            res = np.fromstring(gz.read(cimg), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, 1))\n",
    "\n",
    "def try_download(dataSrc, labelsSrc, cimg):\n",
    "    data = loadData(dataSrc, cimg)\n",
    "    labels = loadLabels(labelsSrc, cimg)\n",
    "    return np.hstack((data, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eeb4156ee788>:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  res = np.fromstring(gz.read(cimg * crow * ccol), dtype = np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Done.\n",
      "Downloading test data\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-eeb4156ee788>:46: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  res = np.fromstring(gz.read(cimg), dtype = np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# URLs for the train image and label data\n",
    "url_train_image = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "url_train_labels = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "num_train_samples = 60000\n",
    "\n",
    "print(\"Downloading train data\")\n",
    "train = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "# URLs for the test image and label data\n",
    "url_test_image = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "url_test_labels = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "num_test_samples = 10000\n",
    "\n",
    "print(\"Downloading test data\")\n",
    "test = try_download(url_test_image, url_test_labels, num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (60000, 784)\n",
      "Test features shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train[:,-1]\n",
    "train_data = train[:,:-1]\n",
    "test_labels = test[:,-1]\n",
    "test_data = test[:,:-1]\n",
    "print('Train features shape:', train_data.shape)\n",
    "print('Test features shape:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of nearest-neighbors\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate PQKNN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing the train_data to PQKNN classifier took 25.09275221824646 seconds.\n"
     ]
    }
   ],
   "source": [
    "pqknn = ProductQuantizationKNN(7, 4)\n",
    "\n",
    "start = time.time()\n",
    "pqknn.compress(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Compressing the train_data to PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $c$=4, we use np.uint8 (thus 1 byte) to store the centroid_ids in the compressedData array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data shape: (60000, 7)\n",
      "Compressed data in bytes: 420000\n",
      "Original data in bytes: 47040000\n",
      "Compression factor: 112.0\n"
     ]
    }
   ],
   "source": [
    "print('Compressed data shape:', pqknn.compressed_data.shape)\n",
    "print('Compressed data in bytes:', pqknn.compressed_data.nbytes)\n",
    "print('Original data in bytes:', train_data.nbytes)\n",
    "print('Compression factor:', train_data.nbytes / pqknn.compressed_data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test_data with PQKNN classifier took 7.444230079650879 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "preds = pqknn.predict(test_data, k)\n",
    "end = time.time()\n",
    "print('Predicting the test_data with PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.35%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, preds)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we increase the number of clusters ($c$), then the accuracy increases (together with the storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing the train_data to PQKNN classifier took 132.7194163799286 seconds.\n"
     ]
    }
   ],
   "source": [
    "pqknn = ProductQuantizationKNN(7, 9)\n",
    "\n",
    "start = time.time()\n",
    "pqknn.compress(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Compressing the train_data to PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $c$=9, we use np.uint16 (thus 2 bytes) to store the centroid_ids in the compressedData array  \n",
    "-> Resulting in twice the storage size of the example above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data shape: (60000, 7)\n",
      "Compressed data in bytes: 840000\n",
      "Original data in bytes: 47040000\n",
      "Compression factor: 56.0\n"
     ]
    }
   ],
   "source": [
    "print('Compressed data shape:', pqknn.compressed_data.shape)\n",
    "print('Compressed data in bytes:', pqknn.compressed_data.nbytes)\n",
    "print('Original data in bytes:', train_data.nbytes)\n",
    "print('Compression factor:', train_data.nbytes / pqknn.compressed_data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test_data with PQKNN classifier took 15.732435703277588 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "preds = pqknn.predict(test_data, k)\n",
    "end = time.time()\n",
    "print('Predicting the test_data with PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.6%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, preds)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With some significantly smaller space we obtain a (good) accuracy between the first and the second example. With a very good compression factor and fast compression and predict time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing the train_data to PQKNN classifier took 58.23953890800476 seconds.\n"
     ]
    }
   ],
   "source": [
    "pqknn = ProductQuantizationKNN(4, 8)\n",
    "\n",
    "start = time.time()\n",
    "pqknn.compress(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Compressing the train_data to PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $c$=8, we use np.uint8 (thus 1 byte) to store the centroid_ids in the compressedData array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed data shape: (60000, 4)\n",
      "Compressed data in bytes: 240000\n",
      "Original data in bytes: 47040000\n",
      "Compression factor: 196.0\n"
     ]
    }
   ],
   "source": [
    "print('Compressed data shape:', pqknn.compressed_data.shape)\n",
    "print('Compressed data in bytes:', pqknn.compressed_data.nbytes)\n",
    "print('Original data in bytes:', train_data.nbytes)\n",
    "print('Compression factor:', train_data.nbytes / pqknn.compressed_data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test_data with PQKNN classifier took 7.140597343444824 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "preds = pqknn.predict(test_data, k)\n",
    "end = time.time()\n",
    "print('Predicting the test_data with PQKNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.08%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, preds)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate SKlearn K-NN approach on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the train_data to SKlearn KNN classifier took 13.833713054656982 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN = KNeighborsClassifier(n_neighbors=k) #n_jobs is now 1\n",
    "\n",
    "start = time.time()\n",
    "kNN.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Fitting the train_data to SKlearn KNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test_data with SKlearn KNN classifier took 561.5949828624725 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "preds = kNN.predict(test_data)\n",
    "end = time.time()\n",
    "print('Predicting the test_data with SKlearn KNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, preds)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the train_data to SKlearn KNN classifier took 12.972641468048096 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kNN = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "kNN.fit(train_data, train_labels)\n",
    "end = time.time()\n",
    "print('Fitting the train_data to SKlearn KNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the test_data with SKlearn KNN classifier took 209.55382823944092 seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "preds = kNN.predict(test_data)\n",
    "end = time.time()\n",
    "print('Predicting the test_data with SKlearn KNN classifier took ' + str(end - start) + ' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, preds)*100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
